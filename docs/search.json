[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECON 355: Regression Analysis",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site is the center for online portions of Regression 355, taught by Kelsey Carlston at Gonzaga University."
  },
  {
    "objectID": "02_assignments/lab-03.html",
    "href": "02_assignments/lab-03.html",
    "title": "Lab 3: Introduction to R",
    "section": "",
    "text": "In this lab, you will learn\n\nhow to use RStudio\nhow to make a plot with R\nhow to do math in R, create objects, use functions, etc.,\nins and outs of a typical workflow in R\n\n\n\n\nNo additional packages required this week.\n\n\n\n\nhouse prices\ncounty elections\n\n\n\n\nFor this assignment, the only thing you will turn in on Canvas is a brief write up detailed at the end of the assignment. You will use R to create some statistics based on a new dataset."
  },
  {
    "objectID": "02_assignments/lab-03.html#working-in-rstudio",
    "href": "02_assignments/lab-03.html#working-in-rstudio",
    "title": "Lab 3: Introduction to R",
    "section": "Working in RStudio",
    "text": "Working in RStudio\n\n\nIf you are going to do anything with R, RStudio is hands-down the best place to do it. RStudio is an open-source integrated development environment (or IDE) that makes programming in R simpler, more efficient, and most importantly, more reproducible. Some of its more user-friendly features are syntax highlighting (it displays code in different colors depending on what it is or does, which makes it easier for you to navigate the code that you’ve written), code completion (it will try to guess what code you are attempting to write and write it for you), and keyboard shortcuts for the more repetitive tasks.\n\nPane layout\nWhen you first open RStudio, you should see three window panes: the Console, the Environment, and the Viewer. If you open an R script, a fourth Source pane will also open. The default layout of these panes is shown in the figure above.\n\nSource. The Source pane provides basic text editing functionality, allowing you to create and edit R scripts. Importantly, you cannot execute the code in these scripts directly, but you can save the scripts that you write as simple text files. A dead give away that you have an R script living on your computer is the .R extension, for example, my_script.R.\n\nConsole. The Console pane, as its name suggests, provides an interface to the R console, which is where your code actually gets run. While you can type R code directly into the console, you can’t save the R code you write there into an R script like you can with the Source editor. That means you should reserve the console for non-essential tasks, meaning tasks that are not required to replicate your results.\nEnvironment. The Environment pane is sort of like a census of your digital zoo, providing a list of its denizens, i.e., the objects that you have created during your session. This pane also has the History tab, which shows the R code you have sent to the console in the order that you sent it.\n\nViewer. The Viewer pane is a bit of a catch-all, including a Files tab, a Plots tab, a Help tab, and a Viewer tab.\n\nThe Files tab works like a file explorer. You can use it to navigate through folders and directories. By default, it is set to your working directory.\nThe Plots tab displays any figures you make with R.\nThe Help tab is where you can go to find helpful R documentation, including function pages and vignettes.\n\n\nLet’s try out a few bits of code just to give you a sense of the difference between Source and Console.\n\nAs you work through this lab, you can practice running code in the Console, but make sure to do the actual exercises in an R script.\n\n\n\nExercises\n\nFirst, let’s open a new R script. To open an R script in RStudio, just click File > New File > R Script (or hit Ctrl + Shift + N, Cmd + Shift + N on Mac OS).\nCopy this code into the console and hit Enter.\n\n\nrep(\"Boba Fett\", 5)\n\n\nNow, copy that code into the R script you just opened and hit Enter again. As you see, the code does not run. Instead, the cursor moves down to the next line. To actually run the code, put the cursor back on the line with the code, and hit Ctrl + Enter (CMD + Enter on Mac OS)."
  },
  {
    "objectID": "02_assignments/lab-03.html#load-in-some-data",
    "href": "02_assignments/lab-03.html#load-in-some-data",
    "title": "Lab 3: Introduction to R",
    "section": "Load in some data",
    "text": "Load in some data\nWe will load in the data “house_prices.csv”, which is posted on Canvas. Save the data into a folder, preferably the same folder as where you are saving your R-script.\n\nSet the working directory\nYou need to tell R what file folder you will be working out of. You can do this in two ways: 1. Go to the “Files” tab in the Viewer pane. Navigate to your folder, then hit the “More” icon, then select “Set As Working Directory”. Since you will want anybody who runs your code to set their working directory, copy the code from the console into your\n2. Type the following code, but instead of your_file_path type the actual folder. Make sure your slashes are forward slashes ( / ) and not back slashes ( \\ ).\n\nsetwd(\"your_file_path\")\n\nFor example, in my script I will type the following, since that’s the folder I’m keeping my data in.\n\nsetwd(\"G:/My Drive/Classes/2023_Spring_ECON_355_Regression/Week 4 - Descriptive Statistics Continued\")\n\n\n\nLoad in the data\nNow that R knows where we have the data stored, we can load the data in.\n\nhouse <- read.csv(\"data/house_prices.csv\")\n\nNote that I have my data in a subfolder of my working directory called “data”. Your code may look more like this:\n\nhouse <- read.csv(\"house_prices.csv\")\n\nThis tells R to read in the csv and call the data frame “house”. You should see the data pop up in your environment. You can click on the word “house” and it will open up the data in the data viewer for you to explore. Or, if you just want a quick look, you can hit the little blue circle with the arrow next to the word “house”.\n\n\nWe can also ask R to print the first few lines of a dataframe to show us what it looks like. In this case, each row represents a house.\n\nhead(house, n = 5) # The 5 tells R to print 5 rows\n\n   Price Living.Area Bathrooms Age Fireplace Bedrooms\n1 142212        1982         1 133         0        3\n2 134865        1676         2  14         1        3\n3 118007        1694         2  15         1        3\n4 138297        1800         1  49         1        2\n5 129470        2088         1  29         1        3\n\n\nThe Price is how much the house sold for. The Living.Area is the number of square feet the house had. We also have the number of Bathrooms and Bedrooms. Finally, we have the Age of the house and whether it has a Fireplace.\n\n\nCreate some descriptive statistics\nR can work as a calculator. Let’s try a few simple exercises. What is the mean and standard deviation of house price? Note that we have to tell R what data frame we’re getting the variable from (in this case “house”), then put a $ to let R know we’re retrieving an element of the data frame (in this case “Price”).\n\nmean(house$Price)\n\n[1] 167901.9\n\nsd(house$Price)\n\n[1] 77158.35"
  },
  {
    "objectID": "02_assignments/lab-03.html#make-your-first-plot",
    "href": "02_assignments/lab-03.html#make-your-first-plot",
    "title": "Lab 3: Introduction to R",
    "section": "Make Your First Plot!",
    "text": "Make Your First Plot!\nTo ease you into working with R, let’s visualize some data to answer a simple question: Is the price of a house related to its square footage? Don’t worry about understanding all of this! It’s just to give you a feel for the sort of graphics you can make with R. We’ll spend a future lab learning how to make even better graphics.\n\nThe plot() function\nThe base R graphics package provides a generic function for plotting, which - as you might have guessed - is called plot(). (“Base R” means it’s automatically loaded and you don’t have to install it.) To see how it works, try running this code:\n\nplot(house$Living.Area, house$Price)\n\n\n\n\n\n\nCustomizing your plot\nWith the plot() function, you can do a lot of customization to the resulting graphic. For instance, you can modify all of the following:\n\npch will change the point type,\nmain will change the main plot title,\nxlab and ylab will change the x and y axis labels,\ncex will change the size of shapes within the plot region,\npch will change the type of point used (you can use triangles, squares, or diamonds, among others),\ncol changes the color of the point (or its border), and\nbg changes the color of the point fill (depending on the type of point it is)\n\nFor instance, try running this code:\n\nplot(\n  house$Living.Area,\n  house$Price,\n  pch = 21,\n  bg = \"darkorange\",\n  col = \"darkred\",\n  cex = 2\n)\n\n\n\n\n\n\nExercises\n\nComplete the following line of code to preview only the first three rows of the house table.\n\n\nhead(house, n = )\n\n\nModify the code below to change the size (cex) of the points from 2 to 1.5.\n\n\nplot(\n  house$Living.Area,\n  house$Price,\n  pch = 21,\n  bg = \"darkorange\",\n  col = \"darkred\",\n  cex = 2\n)\n\n\nWhat does this plot tell us about the relationship between house size and price? Is it positive or negative? Or is there no relationship at all? If there is a relationship, what might explain it?\nComplete the code below to add “Scatter Plot of House Size and Price” as the main title.\n\n\nplot(\n  house$Living.Area,\n  house$Price,\n  pch = 21,\n  bg = \"darkorange\",\n  col = \"darkred\",\n  cex = 1,\n  main = \n)\n\n\nComplete the code below to add “House size (sq. ft.)” as the x-axis label and “Price ($)” as the y-axis label.\n\n\nplot(\n  house$Living.Area,\n  house$Price,\n  pch = 21,\n  bg = \"darkorange\",\n  col = \"darkred\",\n  cex = 2,\n  main = \"Scatter Plot of House Size and Price\",\n  xlab = ,\n  ylab = \n)"
  },
  {
    "objectID": "02_assignments/lab-03.html#r-basics",
    "href": "02_assignments/lab-03.html#r-basics",
    "title": "Lab 3: Introduction to R",
    "section": "R Basics",
    "text": "R Basics\n\nR is a calculator\nYou can just do math with it:\n\n300 * (2/25)\n\n[1] 24\n\n3^2 + 42\n\n[1] 51\n\nsin(17)\n\n[1] -0.9613975\n\n\n\n\nObjects and Functions\nBut, R is more than just a calculator. There are a lot of things you can make with R, and a lot of things you can do with it. The things that you make are called objects, and the things that you do with objects are called functions. Any complex statistical operation you want to conduct in R will almost certainly involve the use of one or more functions.\n\nCalling functions\nTo use a function, we call it like this:\n\nfunction_name(arg1 = value1, arg2 = value2, ...)\n\nTry calling the seq() function.\n\nseq(from = 1, to = 5)\n\n[1] 1 2 3 4 5\n\n\nAs you can see, this generates a sequence of numbers starting at 1 and ending at 5. There are two things to note about this. First, we do not have to specify the arguments explicitly, but they must be in the correct order:\n\nseq(1, 5) \n\n[1] 1 2 3 4 5\n\nseq(5, 1)\n\n[1] 5 4 3 2 1\n\n\nSecond, the seq() function has additional arguments you can specify, like by and length. While we do not have to specify these because they have default values, you can change one or the other (but not at the same time!):\n\nseq(1, 10, by = 2)\n\n[1] 1 3 5 7 9\n\nseq(1, 10, length = 3)\n\n[1]  1.0  5.5 10.0\n\n\n\n\nCreating objects\nTo make an object in R, you use the arrow, <-, like so:\n\nobject_name <- value\n\nTry creating an object with value 5.137 and assigning it to the name bob, like this:\n\nbob <- 5.137\n\nThere are three things to note here. First, names in R must start with a letter and can only contain letters, numbers, underscores, and periods.\n\n# Good\nwinter_solder <- \"Buckey\"\nobject4 <- 23.2\n\n# Bad\nwinter soldier <- \"Buckey\" # spaces not allowed\n4object <- 23.2            # cannot start with a number\n\nSecond, when you create an object with <-, it ends up in your workspace or environment (you can see it in the RStudio environment pane). Finally, it is worth noting that the advantage of creating objects is that we can take the output of one function and pass it to another.\n\nx <- seq(1, 5, length = 3)\n\nlogx <- log(x)\n\nexp(logx)\n\n[1] 1 3 5\n\n\n\n\n\nExercises\n\nUse seq() to generate a sequence of numbers from 3 to 12.\nUse seq() to generate a sequence of numbers from 3 to 12 with length 25.\nWhy doesn’t this code work?\n\n\nseq(1, 5, by = 2, length = 10)\n\n\nUse <- to create an object with value 25 and assign it to a name of your choice.\nNow try to create another object with a different value and name.\nWhat is wrong with this code?\n\n\n2bob <- 10"
  },
  {
    "objectID": "02_assignments/lab-03.html#assignment",
    "href": "02_assignments/lab-03.html#assignment",
    "title": "Lab 3: Introduction to R",
    "section": "Assignment",
    "text": "Assignment\nNow it’s time to work on your own. Download the “County_Election.csv” data set from Canvas and put it in your working directory. Read in the data using read.csv(). Then, write a paragraph giving some information on the data that you find interesting. Include at least 3 statistics and one graph. Be sure to interpret what you think the significance of the statistic is.\nHere is a table describing the variables in the data set:\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nstate\nState FIPS Code\n\n\ncounty\nCounty FIPS Code\n\n\ncounty_name\nCounty Name\n\n\nstate_name\nState Name\n\n\nfips\nCombined FIPS Code\n\n\npct_republican_2016\nPercent of voters in county that voted Republican in 2016 presidential election\n\n\nfrac_coll_plus2010\nPercent of adults 25 years or older who have a 4-year college degree or more in 2010\n\n\nforeign_share2010\nNumber of foreign born residents in the 2010 Census divided by the sum of native and foreign born residents.\n\n\nmed_hhinc2016\nMedian household income in 2016\n\n\npoor_share2010\nShare of families with incomes under the poverty line in 2010\n\n\nshare_black2010\nShare of people who are Black in 2010\n\n\nshare_hisp2010\nShare of people who are Hispanic in 2010\n\n\nshare_asian2010\nShare of people who are Asian in 2010\n\n\nrent_twobed2015\nThe median gross rent for renter-occupied housing units with two\n\n\npopdensity2010\nNumber of residents per square mile in 2010\n\n\nann_avg_job_growth_2004_2013\nAverage annualized job growth rate over the time period 2004 to 2013\n\n\n\nYou may want to do different statistics from what we did above. Here are some functions you can use. To get information about them, type a question mark followed by the function you are looking up into the console. Alternatively, look the function up online.\n\nStatistics\n\n\n\nStatistic\nFunction\n\n\n\n\nMinimum:\nmin()\n\n\nMaximum:\nmax()\n\n\nAverage:\nmean()\n\n\nStandard Deviation:\nsd()\n\n\nMedian:\nmedian()\n\n\nPercentiles:\nquantile()\n\n\nCorrelation Coefficient:\ncor()\n\n\nFrequency tables:\ntable()\n\n\nRelative Frequency tables:\nprop.table()\n\n\n\nNote that in frequency tables you can use more than one variable!\n\n\nGraphics\n\n\n\nPlot\nFunction\n\n\n\n\nBar chart:\nbarplot()\n\n\nHistogram:\nhist()\n\n\nBox plots:\nboxplot()\n\n\nScatter plot:\nplot()"
  },
  {
    "objectID": "02_assignments/lab-04.html#outline",
    "href": "02_assignments/lab-04.html#outline",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "Outline",
    "text": "Outline\n\nObjectives\nIn this lab, you will learn how to:\n\nload R packages with library()\nsubset data\nmerge data\nvisualize data with the grammar of graphics and ggplot()\n\naesthetic mappings\ngeometric objects\nfacets\nscales\nthemes\n\n\n\n\nR Packages\nggplot2\nviridis\n\n\nData\n\nhouse prices\ncounty elections\n\n\n\nGrade\nFor this assignment, you will complete a quiz as you work through the lab."
  },
  {
    "objectID": "02_assignments/lab-04.html#the-library",
    "href": "02_assignments/lab-04.html#the-library",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "The Library",
    "text": "The Library\nR is an extensible programming language, meaning you can write R code to extend the functionality of base R. To share that code, R users will often bundle it into a package, a collection of functions, data, and documentation. You can think of packages as apps, but apps specifically designed for R. To make the functionality a package offers available in R, you have to load them in with the library() function (the technical term is attach).\nYou should always, always, always load all the packages you use at the beginning of a document. That way, people who read your code know exactly what packages you are using all at once and right away. To make this really, really explicit, I prefer to put it with other front matter that I call the “R Preamble.” In an R Script, it looks like this:\n\n### Lab 4: More Advanced R ###\n# This code manipulates data and creates graphs using ggplot\n\nsetwd(\"G:/My Drive/Teaching/regression/02_assignments\")\n\nlibrary(ggplot2)\nlibrary(viridis)\n\nOf course, these aren’t just automatically on your computer, so you have to install the packages first. Then you can open them in R. To do that, you use the function install.packages(). For the packages used today, you can use this call just once like so:\n\ninstall.packages(\n  c(\"ggplot2\", \"viridis\")\n)\n\nNote that you only need to run this once, so don’t put this as a line in your R script document, which you might render multiple times. Just run it in the console.\n\nExercises\nOpen a new R script and add the R Preamble with an R code chunk with the library calls that load the R packages required for this lab. Now actually run each library() call. You can do that by either highlighting them and hitting Ctrl + Enter (Cmd + Enter) or by clicking the run button. If you don’t highlight, R will run the code from the line your cursor is on."
  },
  {
    "objectID": "02_assignments/lab-04.html#load-in-the-data",
    "href": "02_assignments/lab-04.html#load-in-the-data",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "Load in the data",
    "text": "Load in the data\nYou should have already set up your working directory at the top of the sheet. In that folder, you should have the two datasets we will be using in this lab: “NBA_Data.csv” and “Five38_Data.csv”, which you can find on Canvas. Load them in using the read.csv() function.\n\nNBA <- read.csv(\"data/NBA_Data.csv\")\nFive38 <- read.csv(\"data/Five38_Data.csv\")\n\nIf you look in your environment, you should have two data frames. Explore the data a little bit using the functions head(NBA) and summary(NBA). You can use the same functions for the Five38 dataset.\nThe NBA dataset has statistics for all 30 NBA teams for the 2022-2023 season (updated to 2/13/2023), including wins, losses, total points, free throws, assists, turnovers, etc. It also includes whether the team was in the playoffs last year.\nThe Five38 dataset has the conference each team is in, plus the Five38 Elo predictions for whether the team will make playoffs, make finals, and win finals. It also includes the number of times each team has been in the playoffs since 1946.\n\nMake a new column\nYou may notice that the NBA dataset has wins and losses, but it doesn’t have the win percent. We will make that ourselves! To create a new column, we just have to tell R what to do. Remember that we have to tell R which data frame we are using, then put a dollar sign to say we are accessing a specific variable.\n\nNBA$win_pct = NBA$Wins/NBA$Games_Played\n\nEasy! We can explore this variable a little bit by typing:\n\nsummary(NBA$win_pct)\n\nNice! Now we know that the median team lost about 50 percent of its games. Even the best team only won 72 percent.\n\n\n\n\n\nExercises\n\nMake a new column that shows the average points per game, which is points (NBA$Points) divided by the total games (NBA$Games_Played).\nFind the mean and median of points scored per game.\nUse the cor() function to find the correlation between points per game and the win percent."
  },
  {
    "objectID": "02_assignments/lab-04.html#merging-data",
    "href": "02_assignments/lab-04.html#merging-data",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "Merging data",
    "text": "Merging data\nTo merge data, we need a unique identifier that matches between the two datasets, just like in any program. Take a look at the team names. What’s the problem?\nThe team names in the Five38 dataset are split to place and name. We can combine those columns using the following code:\n\nFive38$Team <- paste(Five38$Place, Five38$Name, sep = \" \")\n\nThe paste function tells R that we are combining two strings. The sep = \" \" option tells R that we want a space between the two strings, but we could put a comma or no space if we wanted.\nNow we have a unique ID, and we can use it to merge our datasets. We will create a new dataset called BBall with our merged data.\n\nBBall <- merge(NBA, Five38, by = \"Team\")\n\nThis new dataset has the same 30 teams, but 31 variables rather than 7 or 25. (It’s not 7 + 25 = 32 because R doesn’t repeat the identifier.)"
  },
  {
    "objectID": "02_assignments/lab-04.html#subsetting-data",
    "href": "02_assignments/lab-04.html#subsetting-data",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "Subsetting Data",
    "text": "Subsetting Data\nA common thing to do with data is subset the data into a smaller group of data. For instance, we might want to remove some columns if there are columns we don’t need. Or, we might want to do some calculations on only teams in the Western Conference. Or, maybe we want to do calculations on the teams that have over 50% win percent.\nIf we are subsetting the whole dataframe, we put square brackets next to the name of the dataframe and give it the [rows, columns]. For example, if we want the second row of the first column, we would type BBall[2,1]. If we want the entire 4th column, we would put BBall[,4]. And if we want the entire 8th row, we would write BBall[8,].\nWe can also subset a range of rows or columns. To get the first 5 columns, we would type BBall[,1:5].\nTo subset by the conference, we would use two equals signs to tell R that we are checking for equivalency. (One equals sign means we are assigning the value.) Let’s make a new dataframe that only includes the Western conference.\n\nwest <- BBall[BBall$Conference == \"West\",]\n\nNow, we could do whatever we wanted on the new “west” dataframe.\nWe don’t have to make a new dataframe to use functions. For example, let’s say we want the average number of rebounds for teams that have over a 50% win rate vs under or equal to a 50% win rate. We are going to call the mean function on rebounds. Since we are targeting just one column, we only have to put the row argument into the square brackets.\n\nmean(BBall$Rebounds[BBall$win_pct > 0.5])\nmean(BBall$Rebounds[BBall$win_pct <= 0.5])\n\nGreat! Now, let’s subset to find the mean number of turnovers for teams that are in the Eastern Conference and have at least 113 points per game. We will use the ampersand (&) to tell R that we want both conditions to be true to include it. We can compare that to the number of turnovers for teams in the Eastern Conference that have less than 113 points per game.\n\nmean(BBall$Turnovers[BBall$Conference == \"East\" & BBall$points_per_game >= 113])\nmean(BBall$Turnovers[BBall$Conference == \"East\" & BBall$points_per_game < 113])\n\nWe can also get columns by name. Let’s make a a new dataset that just includes the team name and our calculated columns.\n\nnew = BBall[,c(\"Team\", \"win_pct\", \"points_per_game\")]\n\nOne thing we might want to know is what the name of the maximum value is. We can use the function which.max(), which gives the position/row number of the biggest value. Then we can return that row number. For example, if we want to know which team has the biggest win percent we would use this code:\n\nBBall$Team[which.max(BBall$win_pct)]\n\n\nExercise\n\nWhat is the value in the 3rd row of the 9th column of the BBall dataset?\nWhat is the mean win percentage in the Western Conference?\nWhat is the average free throw percent for teams in the Western conference that have at least 1120 personal fouls?\nWhich team has been to the playoffs the most times?"
  },
  {
    "objectID": "02_assignments/lab-04.html#graphics",
    "href": "02_assignments/lab-04.html#graphics",
    "title": "Lab 4: ggplot and Data Manipulation",
    "section": "Graphics",
    "text": "Graphics\n\nThe Grammar of Graphics\nIt’s easy to imagine how you would go about with pen and paper drawing a bar chart of the number of games played in each conference. But, what if you had to dictate the steps to make that graph to another person, one you can’t see or physically interact with? All you can do is use words to communicate the graphic you want. How would you do it? The challenge here is that you and your illustrator must share a coherent vocabulary for describing graphics. That way you can unambiguously communicate your intent. That’s essentially what the grammar of graphics is, a language with a set of rules (a grammar) for specifying each component of a graphic.\nNow, if you squint just right, you can see that R has a sort of grammar built-in with the base graphics package. To visualize data, it provides the default plot() function, which you learned about in the last lab. This is a workhorse function in R that will give you a decent visualization of your data fast, with minimal effort. It does have its limitations though. For starters, the default settings are, shall we say, less than appealing. I mean, they’re fine if late-nineties styles are your thing, but less than satisfying if a more modern look is what you’re after. Second, taking fine-grained control over graphics generated with plot() can be quite frustrating, especially when you want to have a faceted figure (a figure with multiple plot panels).\nThat’s where the ggplot2 package comes in. It provides an elegant implementation of the grammar of graphics, one with more modern aesthetics and with a more standardized framework for fine-tuning figures, so that’s what we’ll be using here. From time to time, I’ll try to give you examples of how to do things with the plot() function, too, so you can speak sensibly to the die-hard holdouts, but we’re going to focus on learning ggplot.\n\n\n\n\n\n\nResources for ggplot2\n\n\n\nThere are several excellent sources of additional information on statistical graphics in R and statistical graphics in general that I would recommend.\n\nThe website for the ggplot2 package. This has loads of articles and references that will answer just about any question you might have.\nThe R graph gallery website. This has straightforward examples of how to make all sorts of different plot visualizations, both with base R and ggplot.\nClaus Wilke’s free, online book Fundamentals of Data Visualization, which provides high-level rules or guidelines for generating statistical graphics in a way that clearly communicates its meaning or intent and is visually appealing.\nThe free, online book ggplot2: Elegant Graphics for Data Analysis (3ed) by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen. This is a more a deep dive into the grammar of graphics than a cookbook, but it also has lots of examples of making figures with ggplot2.\n\n\n\nSo, to continue our analogy above, we’re going to treat R like our illustrator, and ggplot2 is the language we are going to speak to R to visualize our data. So, how do we do that? Well, let’s start with the basics. Suppose we want to know if there’s some kind of relationship between the field goal percent and the probability of making playoffs. Here’s how we would visualize that.\n\nggplot(data = BBall) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs)\n  )\n\nHere, we have created a scatterplot, a representation of the raw data as points on a Cartesian grid. There are several things to note about the code used to generate this plot.\n\nIt begins with a call to the ggplot() function. This takes a data argument. In this case, we say that we want to make a plot to visualize the basketball data.\nThe next function call is geom_point(). This is a way of specifying the geometry we want to plot. Here we chose points, but we could have used another choice (lines, for example, or polygons).\nThe geom_point() call takes a mapping argument. You use this to specify how variables in your data are mapped to properties of the graphic. Here, we chose to map the Field_Goal_Pct variable to the x-coordinates and the Making_Playoffs variable to the y-coordinates. Importantly, we use the aes() function to supply an aesthetic to the mapping parameter. This is always the case.\nThe labs() function allows us to specific axis lables and titles. In this instance, I’m only using it to create alternative text for accessibility.\nThe final thing to point out here is that we combined or connected these arguments using the plus-sign, +. You should read this literally as addition, as in “make this ggplot of the basketball data and add a point geometry to it.” Be aware that the use of the plus-sign in this way is unique to the ggplot2 package and won’t work with other graphical tools in R.\n\nWe can summarize these ideas with a simple template. All that is required to make a graph in R is to replace the elements in the bracketed sections with a dataset, a geometry function, and an aesthetic mapping.\n\nggplot(data = <DATA>) + \n  <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n\nOne of the great things about ggplot, something that makes it stand out compared to alternative graphics engines in R, is that you can assign plots to a variable and call it in different places, or modify it as needed.\n\nplayoffs_plot <- ggplot(data = BBall) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs)\n  )\n\nplayoffs_plot\n\n\n\nExercises\n\nRecreate the scatterplot above, but switch the axes. Put win percent on the x axis and times in playoffs on the y axis.\nNow create a scatterplot of win percent on the x axis and probability of making playoffs (Making_Playoffs) on the y axis.\n\n\n\nAesthetics\nIn the plot above, we only specified the position of the points (the x- and y-coordinates) in the aesthetic mapping, but there are many aesthetics (see the figure below), and we can map the same or other variables to those.\n\n\nConsider, for example, that we have two groups of teams: those that went to the playoffs last year and those that had no post season. Do we think that the relationship between the field goal percent and probability of making playoffs are the same for both? Let’s add conference to our aesthetic mapping (specifically to the color parameter) and see what happens.\n\nggplot(data = BBall) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Last_Year)\n  )\n\nNotice that ggplot2 automatically assigns a unique color to each category and adds a legend to the right that explains each color. In this way, the color doesn’t just change the look of the figure. It conveys information about the data. Rather than mapping a variable in the data to a specific aesthetic, though, we can also define an aesthetic manually for the geometry as a whole. In this case, the aesthetics do not convey information about the data. They merely change the look of the figure. The key to doing this is to move the specification outside the aes(), but still inside the geom_point() function.\n\nggplot(data = BBall) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs),\n    shape = 21,\n    size = 4,\n    color = \"darkred\",\n    fill = \"darkgoldenrod1\"\n  )\n\nNotice that we specified the shape with a number. R has 25 built-in shapes that you can specify with a number, as shown in the figure below. Some important differences in these shapes concern the border and fill colors. The hollow shapes (0-14) have a border that you specify with color, the solid shapes (15-20) have a border and fill, both specified with color, and the filled shapes (21-24) have separate border and fill colors, specified with color and fill respectively.\n\n\n\n\n\n\n\n\nTip\n\n\n\nNote that you can use hexadecimal codes like #004F2D instead of “forestgreen” to specify a color. This also allows you to specify a much wider range of colors. See this color picker website for one way of exploring colors.\n\n\n\n\nExercises\n\nChange the code below to map the Last_Year variable to the x-axis (in addition to the color).\n\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Last_Year)\n  )\n\n\nWhat does this do to the position of the points?\nChange the code below to map the Last_Year variable to the shape aesthetic (in addition to the color).\n\n\n# hint: use shape = ...\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Last_Year)\n  )\n\n\nChange the code below to map the Last_Year variable to the size aesthetic (replacing color).\n\n\n# hint: use size = ...\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Last_Year)\n  )\n\n\nFor the following code, change the color, size, and shape aesthetics for the entire geometry (do not map them to the data).\n\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs),\n    color = , # <------- insert value here\n    size = ,  # <------- \n    shape =   # <------- \n  )\n\n\n\nGeometries\nHave a look at these two plots.\n\n\n\nBoth represent the same data and the same x and y variables, but they do so in very different ways. That difference concerns their different geometries. As the name suggests, these are geometrical objects used to represent the data. To change the geometry, simply change the geom_*() function. For example, to create the plots above, use the geom_point() and geom_smooth() functions.\n\nggplot(data = BBall) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n  )\n\nggplot(data = BBall) +\n  geom_smooth(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n  )\n\nWhile every geometry function takes a mapping argument, not every aesthetic works (or is needed) for every geometry. For example, there’s no shape aesthetic for lines, but there is a linetype. Conversely, points have a shape, but not a linetype.\n\nggplot(data = BBall) + \n  geom_smooth(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct, linetype = Last_Year),\n  )\n\nOne really important thing to note here is that you can add multiple geometries to the same plot to represent the same data. Simply add them together with +.\n\nggplot(data = BBall) +\n  geom_smooth(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct, linetype = Last_Year)\n  ) +\n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct, color = Last_Year)\n  ) \n\nThat’s a hideous figure, though it should get the point across. While layering in this way is a really powerful tool for visualizing data, it does have one important drawback. Namely, it violates the DRY principle (Don’t Repeat Yourself), as it specifies the x and y variables twice. This makes it harder to make changes, forcing you to edit the same aesthetic parameters in multiple locations. To avoid this, ggplot2 allows you to specify a common set of aesthetic mappings in the ggplot() function itself. These will then apply globally to all the geometries in the figure.\n\nggplot(\n  data = BBall,\n  mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n) +\n  geom_smooth(mapping = aes(linetype = Last_Year)) +\n  geom_point(mapping = aes(color = Last_Year))\n\nNotice that you can still specify specific aesthetic mappings in each geometry function. These will apply only locally to that specific geometry rather than globally to all geometries in the plot. In the same way, you can specify different data for each geometry.\n\nggplot(\n  data = BBall,\n  mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n) +\n  geom_smooth(data = BBall[BBall$Last_Year == \"Playoffs\",]) +\n  geom_point(mapping = aes(color = Last_Year))\n\nSome of the more important geometries you are likely to use include:\n\ngeom_point()\ngeom_line()\ngeom_segment()\ngeom_polygon()\ngeom_boxplot()\ngeom_histogram()\ngeom_density()\n\nWe’ll actually cover those last three in the section on plotting distributions. For a complete list of available geometries, see the layers section of the ggplot2 website reference page.\n\n\nScales\nScales provide the basic structure that determines how data values get mapped to visual properties in a graph. The most obvious example is the axes because these determine where things will be located in the graph, but color scales are also important if you want your figure to provide additional information about your data. Here, we will briefly cover two aspects of scales that you will often want to change: axis labels and color palettes, in particular palettes that are colorblind safe.\n\nLabels\nBy default, ggplot2 uses the names of the variables in the data to label the axes. This, however, can lead to poor graphics as naming conventions in R are not the same as those you might want to use to visualize your data. Fortunately, ggplot2 provides tools for renaming the axis and plot titles. The one you are likely to use most often is probably the labs() function. Here is a standard usage:\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n  ) +\n  labs(\n    x = \"Field Goal Percent\",\n    y = \"Three Point Percent\",\n    title = \"NBA 2022-2023 Season\"\n  )\n\n\n\nColor Pallettes\nWhen you map a variable to an aesthetic property, ggplot2 will supply a default color palette. This is fine if you are just wanting to explore the data yourself, but when it comes to publication-ready graphics, you should be a little more thoughtful. The main reason for this is that you want to make sure your graphics are accessible. For instance, the default ggplot2 color palette is not actually colorblind safe. To address this shortcoming, you can specify colorblind safe color palettes using the scale_color_viridis() function from the viridis package. It works like this:\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Last_Year)\n  ) +\n  labs(\n    x = \"Field Goal Percent\",\n    y = \"Three Point Percent\",\n    title = \"NBA 2022-2023 Season\"\n  ) +\n  scale_color_viridis(\n    option = \"viridis\", \n    discrete = TRUE\n  )\n\nI know it doesn’t look good like it is, but when you are working with more categories or different types of graphs, like maps or stacked bar charts, these kinds of pallettes are very useful.\nHere are the color palettes available in the viridis package: {fig-alt = “The colors available in the viridis package.”}\n\n\n\nExercises\n\nUsing the BBall dataset, plot Steals (y variable) by Personal_Fouls (x variable) and change the axis labels to reflect this.\nUsing the code below, try out some different colorblind safe palettes from the viridis package.\n\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Making_Playoffs, color = Conference)\n  ) +\n  labs(\n    x = \"Field Goal Percent\",\n    y = \"Probability of Making Playoffs\",\n    title = \"NBA 2022-2023 Season\"\n  ) +\n  scale_color_viridis(\n    option = \"viridis\", #<------- change value here \n    discrete = TRUE\n  )\n\n\nTry adding a numeric variable, like win_pct, as the color input. (Make sure to change discrete = TRUE to discrete = FALSE.)\n\n\n\nThemes\nTo control the display of non-data elements in a figure, you can specify a theme. This is done with the theme() function. Using this can get pretty complicated, pretty quick, as there are many many elements of a figure that can be modified, so rather than elaborate on it in detail, I want to draw your attention to pre-defined themes that you can use to modify your plots in a consistent way.\nHere is an example of the black and white theme, which removes filled background grid squares, leaving only the grid lines.\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n  ) +\n  labs(\n    x = \"Field Goal Percent\",\n    y = \"Three Point Percent\",\n    title = \"NBA 2022-2023 Season\"\n  ) +\n  theme_bw()\n\n\n\nExercises\n\nComplete the code below, trying out each separate theme: theme_minimal() theme_classic() theme_void()\n\n\nggplot(data = BBall) + \n  geom_point(\n    mapping = aes(x = Field_Goal_Pct, y = Three_pt_pct)\n  ) +\n  labs(\n    x = \"Field Goal Percent\",\n    y = \"Three Point Percent\",\n    title = \"NBA 2022-2023 Season\"\n  ) +\n  theme_   # <------- complete function call to change theme"
  },
  {
    "objectID": "02_assignments/intro_to_R_blind.html",
    "href": "02_assignments/intro_to_R_blind.html",
    "title": "Introduction to R for Blind Users",
    "section": "",
    "text": "This assignment is meant to be an introduction to R that includes a few points that will be important for blind users. In particular, this will show you how to run R code, how to: * Create a Markdown document * Implement settings that help with a screen reader * Load the BrailleR package and use some of the basic functions"
  },
  {
    "objectID": "02_assignments/lab-05.html",
    "href": "02_assignments/lab-05.html",
    "title": "Lab 5: dplyr and ggplot2",
    "section": "",
    "text": "In this lab, you will\n\nget more practice merging data in R\nlearn some important functions in the dplyr package\npractice making gorgeous plots in ggplot2\nbe encouraged to use help pages and vignettes to learn how to use functions\n\n\n\n\ndplyr\nggplot2\n\n\n\n\nGDP by country\n\nContains GDP per capita (PPP) for each country from 1990 to 2023\n\nPopulation and life expectancy by country\n\nContains population and life expectancy variables for each country from 1950 to 2023\n\n\n\n\n\nFor this assignment, follow along with the quiz on Canvas."
  },
  {
    "objectID": "02_assignments/lab-05.html#dplyr-and-the-tidyverse",
    "href": "02_assignments/lab-05.html#dplyr-and-the-tidyverse",
    "title": "Lab 5: dplyr and ggplot2",
    "section": "Dplyr and the Tidyverse",
    "text": "Dplyr and the Tidyverse\nThere are several packages that make data manipulation in R much easier than in Excel or many other languages. The tidyverse is a collection of R packages designed for data science. It includes tools for data manipulation, visualization, and analysis. Core packages include dplyr for data wrangling, ggplot2 for visualization, tidyr for data tidying, and readr for data import. The tidyverse is built around the concept of tidy data, where datasets are organized in a consistent way, making analysis more intuitive and efficient.\ndplyr is a package used for data manipulation, providing a range of tools to transform, summarize, and manipulate data frames. It allows for operations like filtering rows (filter()), selecting columns (select()), arranging data (arrange()), creating new variables with functions of existing variables (mutate()), and summarizing data (summarize()). These functions make it easy to work with large datasets using clear, readable syntax.\nWe want to read in the data, then merge it to create a dataset that allows us to compare GDP and life expectancy. First, load the packages and read in the data.\n\nrm(list = ls())\nlibrary(tidyverse)\nlibrary(ggplot2)\npop <- read.csv(\"data/population_by_country.csv\") # The csv file is in my \"data\" folder\ngdp <- read.csv(\"data/gdp_by_country.csv\") # You may not need the \"data/\" part\n\nYou will notice that the population dataset has a lot more rows than the GDP dataset. There are two reasons for that:\n1) Population includes many years which we don’t need\n2) GDP is formatted “wide” rather than “long”\nWe will discuss how to adjust those now.\n\nFilter\nOne of the things we can do with dplyr is remove rows we don’t based on criteria we set. For instance, let’s say we want to subset rows so that the data frame only includes data from 1990 to 2023, the years in the GDP data. We can either use the code we previously learned using base R:\n\npop <- pop[pop$Year > 1989, ]\n\nOr, we can use the easier functionality that is a part of dplyr.\n\npop <- filter(pop, Year > 1989)\n\nUsually, rather than using functions in that way, we use something called the piping operator. In R, the piping operator (|>), provided by the magrittr package (and commonly used in the tidyverse), allows you to chain together a sequence of operations in a more readable and intuitive way. The pipe enables you to pass the output of one function directly into the next function as an input, without the need for nesting functions or creating intermediate variables.\nThe basic syntax is:\n\ndata |> function1() |> function2() |> function3()\n\nWhich is equivalent to:\n\nfunction3(function2(funciont1(data)))\n\nThe pipe operator takes the result of the left-hand side and feeds it as the first argument into the function on the right-hand side. This makes the code flow from left to right, mimicking how we read sentences, which often improves readability, especially when performing multiple operations.\nIn our example, the code would be:\n\npop <- pop |> \n  filter(Year > 1989)\n\n\n\nPivot Longer\nIn the GDP dataset, each column is a different year (wide format), while in the life expectancy dataset, there are rows for each year for each country (long format). Usually, long format data is more helpful, so we will change gdp to be long using pivot_longer().\nThe reference pages for tidyverse functions are usually very good, with many helpful examples. They are often vignettes rather than help pages, which means they have more information and are easier to read. Check out the pivot longer vignette to learn about it.\nWe want to turn every column that starts with “X” into a row, with the year in the column name as a new column. So we want this table:\n\n\n\nCountry\nX2000\nX2001\nX2002\n\n\n\n\nUSA\na\nb\nc\n\n\nCanada\nx\ny\nz\n\n\nMexico\nt\nu\nv\n\n\n\nTo turn into this table:\n\n\n\nCountry\nYear\nValue\n\n\n\n\nUSA\n2000\na\n\n\nUSA\n2001\nb\n\n\nUSA\n2002\nc\n\n\nCanada\n2000\nx\n\n\nCanada\n2001\ny\n\n\nCanada\n2002\nz\n\n\nMexico\n2000\nt\n\n\nMexico\n2001\nu\n\n\nMexico\n2002\nv\n\n\n\nWe will use the piping operator to use the function.\n\ngdp <- gdp |> \n  pivot_longer(\n    cols = starts_with(\"X\"),\n    names_to = \"Year\",\n    names_prefix = \"X\",\n    values_to = \"GDP_per_cap\",\n    values_drop_na = TRUE\n  )\n\n\n\n\n\n\n\nMore help with the pivot longer\n\n\n\nCheck out the video on Canvas for more help with pivot longer. There are also videos on Youtube, like this one.\n\n\nIn order to merge, we need to have a key to merge on so we can merge by a unique country/year. We could make a new variable that has both of those, but R allows us to merge based on two keys. The keys do have to be the same data type, so let’s change the Year variable in the GDP data frame to numeric. Then, we can use merge().\nmutate() is a function that allows us to create new row-wise variables within the dplyr framework. (Note that if you use <- in mutate() or summarize(), the variable names can be weird, so you must use =.)\n\ngdp <- gdp |> \n  mutate(Year = as.numeric(Year))\n\nworld <- merge(gdp, pop, by.x = c(\"Year\", \"Country.Code\"), by.y = c(\"Year\", \"iso3_code\"))\n\nNow we can do the analysis we want!"
  },
  {
    "objectID": "02_assignments/lab-05.html#gapminder-analysis",
    "href": "02_assignments/lab-05.html#gapminder-analysis",
    "title": "Lab 5: dplyr and ggplot2",
    "section": "Gapminder Analysis",
    "text": "Gapminder Analysis\nThe Gapminder project reported national income versus health for all of the world countries. The project had many great visualizations, but they stopped updating data in 2015. We are going to update the graphic with new data. Here is a scatterplot of GDP per capita (PPP) and health (life expectancy at birth):\n\n\nLet’s find out which recent years have data for many countries. We will use group_by() and summarize() to do so. The group_by() function in dplyr is used to group data by one or more variables in a data frame. This is useful when you want to perform operations (like summarizing or mutating) separately for each group, rather than on the entire dataset. Grouping doesn’t change the data itself, but it sets the stage for subsequent operations that will respect the groups.\nI’m going to create a new dataframe that groups data by year, and I’ll get the count and average life expectancy for each. Then, I’ll print the most recent years of data, and I’ll do a line plot of life expectancy over time.\n\nyear_data <- world |> \n  group_by(Year) |> \n  summarize(n_countries = n(),\n            avg_le = mean(as.numeric(life_exp_total)))\n\nyear_data[year_data$Year > 2019,]\n\nggplot(data = year_data) +\n  geom_line(aes(x = Year, y = avg_le)) +\n  xlab(\"Year\") +\n  ylab(\"Average Life Expectancy\") +\n  theme_classic() +\n  labs(alt = \"A line graph with year on the x axis and life expectancy on the y axis. Years range from 1990 to 2023, and the average life expecatancy increases from about 65 to about 73, with a dip around 2020.\") # It's a good idea to add alternative text for visually impaired users!\n\nIt looks like 2021 has almost all of the countries in the sample, so we will use that year.\n\nExercise\n\nChange the data type of life_exp_total and total_pop to numeric using as.numeric() within mutate() like we did with year in the GDP dataset.\nSubset the world data to just include the year 2021 using filter().\nTry grouping by “Continent”, and calculate the average life expectancy and GDP per capita for each continent using summarize().\nCalculate the total population by continent using group_by() and sum() within summarize().\nCreate the variable log_gdp by using log() for GDP_per_cap within mutate().\n\n\n\nCreating the scatterplot\nUse ggplot to create a scatterplot of logged GDP versus life expectancy for 2021. Make sure to do the following:\n\nUse arguments within the aes() mapping function to change the color of the points to reflect the continent, and the size of the point to reflect total population. You may need to use help pages or Google to figure it out.\nAdd x and y labels.\nChange the legend label to have a nicer title by using labs(size = \"Whatever you want your size label to be\").\n\n\n\nExercise\nFind out one more interesting thing about the dataset. Maybe you want to plot one of the other variables, like population density or fertility. Or, maybe you want to do some summary statistics like finding the correlation between infant mortality and life expectancy after age 15. What did you find? And why do you think it is interesting?"
  }
]